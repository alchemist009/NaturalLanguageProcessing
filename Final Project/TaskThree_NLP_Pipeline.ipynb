{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy = True\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords, dependency_treebank\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenize this, and call yourself the Tokenizer.']\n",
      "\n",
      "Tokenized text is: \n",
      "['Tokenize', 'this', ',', 'and', 'call', 'yourself', 'the', 'Tokenizer', '.']\n",
      "\n",
      "Text after removal of stop words is: \n",
      "['Tokenize', ',', 'call', 'Tokenizer', '.']\n",
      "\n",
      "POS tagged words are: \n",
      "[('Tokenize', 'VB'), ('this', 'DT'), (',', ','), ('and', 'CC'), ('call', 'VB'), ('yourself', 'PRP'), ('the', 'DT'), ('Tokenizer', 'NNP'), ('.', '.')]\n",
      "\n",
      "Stemming: \n",
      "\n",
      "token\n",
      "thi\n",
      ",\n",
      "and\n",
      "call\n",
      "yourself\n",
      "the\n",
      "token\n",
      ".\n",
      "\n",
      "\n",
      "Lemmatizing: \n",
      "Tokenize\n",
      "this\n",
      ",\n",
      "and\n",
      "call\n",
      "yourself\n",
      "the\n",
      "Tokenizer\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "sentence = \"Tokenize this, and call yourself the Tokenizer.\"\n",
    "sent_text = nltk.sent_tokenize(sentence)\n",
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    \n",
    "filtered_tokenized_text = [word for word in tokenized_text if word not in stopwords.words('english')]\n",
    "#tokens = nltk.word_tokenize(sentence)\n",
    "print(sent_text)\n",
    "print(\"\\nTokenized text is: \")\n",
    "print(tokenized_text)\n",
    "print(\"\\nText after removal of stop words is: \")\n",
    "print(filtered_tokenized_text)\n",
    "print(\"\\nPOS tagged words are: \")\n",
    "print(tagged)\n",
    "\n",
    "print('\\nStemming: \\n')\n",
    "for word in tokenized_text:\n",
    "    print(stemmer.stem(word))\n",
    "print('\\n\\nLemmatizing: ')\n",
    "for word in tokenized_text:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = DependencyGraph(tagged)\n",
    "\n",
    "path_to_jar = '../stanford-corenlp-full-2018-02-27/stanford-corenlp-3.9.1.jar'\n",
    "path_to_models_jar = '../stanford-corenlp-full-2018-02-27/stanford-corenlp-3.9.1-models.jar'\n",
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_112/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('shot', 'VBD'), 'nsubj', ('I', 'PRP')),\n",
       " (('shot', 'VBD'), 'dobj', ('elephant', 'NN')),\n",
       " (('elephant', 'NN'), 'det', ('an', 'DT')),\n",
       " (('shot', 'VBD'), 'nmod', ('sleep', 'NN')),\n",
       " (('sleep', 'NN'), 'case', ('in', 'IN')),\n",
       " (('sleep', 'NN'), 'nmod:poss', ('my', 'PRP$'))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = dependency_parser.raw_parse('I shot an elephant in my sleep')\n",
    "dep = result.__next__()\n",
    "list(dep.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I : [Synset('iodine.n.01'), Synset('one.n.01'), Synset('i.n.03'), Synset('one.s.01')]\n",
      "Hypernym : [Synset('chemical_element.n.01'), Synset('halogen.n.01')]\n",
      "\n",
      "Hyponym : [Synset('iodine-125.n.01'), Synset('iodine-131.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('digit.n.01')]\n",
      "\n",
      "Hyponym : [Synset('monad.n.02'), Synset('singleton.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('letter.n.02')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shot : [Synset('shooting.n.01'), Synset('shot.n.02'), Synset('stroke.n.01'), Synset('shot.n.04'), Synset('shot.n.05'), Synset('scene.n.04'), Synset('injection.n.03'), Synset('nip.n.01'), Synset('shot.n.09'), Synset('guess.n.02'), Synset('snapshot.n.01'), Synset('shot.n.12'), Synset('shot.n.13'), Synset('shot.n.14'), Synset('shot.n.15'), Synset('shot.n.16'), Synset('blastoff.n.01'), Synset('shoot.v.01'), Synset('shoot.v.02'), Synset('blast.v.07'), Synset('film.v.01'), Synset('shoot.v.05'), Synset('dart.v.02'), Synset('tear.v.03'), Synset('shoot.v.08'), Synset('photograph.v.01'), Synset('shoot.v.10'), Synset('shoot.v.11'), Synset('inject.v.03'), Synset('shoot.v.13'), Synset('shoot.v.14'), Synset('fritter.v.01'), Synset('shoot.v.16'), Synset('shoot.v.17'), Synset('shoot.v.18'), Synset('shoot.v.19'), Synset('inject.v.01'), Synset('changeable.s.04')]\n",
      "Hypernym : [Synset('propulsion.n.02')]\n",
      "\n",
      "Hyponym : [Synset('countershot.n.01'), Synset('discharge.n.09'), Synset('gunfire.n.01'), Synset('headshot.n.03'), Synset('potshot.n.01'), Synset('shellfire.n.01'), Synset('shoot.n.02')]\n",
      "\n",
      "Meronym : [Synset('fire_control.n.01')]\n",
      "\n",
      "Hypernym : [Synset('projectile.n.01')]\n",
      "\n",
      "Hyponym : [Synset('bb.n.01'), Synset('bird_shot.n.01'), Synset('grapeshot.n.01'), Synset('musket_ball.n.01')]\n",
      "\n",
      "\n",
      "Holonym : [Synset('case_shot.n.01')]\n",
      "Hypernym : [Synset('maneuver.n.03')]\n",
      "\n",
      "Hyponym : [Synset('baseball_swing.n.01'), Synset('break.n.11'), Synset('carom.n.02'), Synset('cut.n.14'), Synset('golf_stroke.n.01'), Synset('masse.n.01'), Synset('miscue.n.01'), Synset('swipe.n.01'), Synset('tennis_stroke.n.01')]\n",
      "\n",
      "Meronym : [Synset('follow-through.n.02')]\n",
      "\n",
      "Hypernym : [Synset('opportunity.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('expert.n.01')]\n",
      "\n",
      "Hyponym : [Synset('gunman.n.02'), Synset('marksman.n.01'), Synset('trapshooter.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('photograph.n.01')]\n",
      "\n",
      "Hyponym : [Synset('outtake.n.01')]\n",
      "\n",
      "\n",
      "Holonym : [Synset('movie.n.01')]\n",
      "Hypernym : [Synset('medical_care.n.01')]\n",
      "\n",
      "Hyponym : [Synset('intradermal_injection.n.01'), Synset('intramuscular_injection.n.01'), Synset('intravenous_injection.n.01'), Synset('subcutaneous_injection.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('small_indefinite_quantity.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('remark.n.01')]\n",
      "\n",
      "Hyponym : [Synset('cheap_shot.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('estimate.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('photograph.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('sports_equipment.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('charge.n.15')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('blow.n.01')]\n",
      "\n",
      "Hyponym : [Synset('cheap_shot.n.02')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('attempt.n.01')]\n",
      "\n",
      "Hyponym : [Synset('basketball_shot.n.01'), Synset('headshot.n.02'), Synset('slapshot.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('attempt.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('rocket_firing.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('injure.v.01')]\n",
      "\n",
      "Hyponym : [Synset('grass.v.01'), Synset('gun_down.v.01'), Synset('kneecap.v.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('kill.v.01')]\n",
      "\n",
      "Hyponym : [Synset('flight.v.01'), Synset('pick_off.v.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('fire.v.02')]\n",
      "\n",
      "Hyponym : [Synset('blaze_away.v.02'), Synset('gun.v.01'), Synset('open_fire.v.01'), Synset('overshoot.v.01'), Synset('pump.v.02'), Synset('sharpshoot.v.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('record.v.01')]\n",
      "\n",
      "Hyponym : [Synset('reshoot.v.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('project.v.10')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('rush.v.01')]\n",
      "\n",
      "Hyponym : [Synset('plunge.v.03')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('rush.v.01')]\n",
      "\n",
      "Hyponym : [Synset('rip.v.02')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('hit.v.01')]\n",
      "\n",
      "Hyponym : [Synset('birdie.v.01'), Synset('bogey.v.01'), Synset('break.v.40'), Synset('carom.v.02'), Synset('chip.v.03'), Synset('double_bogey.v.01'), Synset('dunk.v.02'), Synset('eagle.v.01'), Synset('knuckle.v.02')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('record.v.01')]\n",
      "\n",
      "Hyponym : [Synset('retake.v.03'), Synset('x-ray.v.02')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('emit.v.02')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('ache.v.03')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('insert.v.02')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('weave.v.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('throw.v.14')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('consume.v.03')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('score.v.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('utter.v.02')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('measure.v.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('grow.v.03')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('administer.v.04')]\n",
      "\n",
      "Hyponym : [Synset('immunize.v.02'), Synset('infuse.v.05')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "an : [Synset('associate_in_nursing.n.01')]\n",
      "Hypernym : [Synset('associate_degree.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "elephant : [Synset('elephant.n.01'), Synset('elephant.n.02')]\n",
      "Hypernym : [Synset('pachyderm.n.01'), Synset('proboscidean.n.01')]\n",
      "\n",
      "Hyponym : [Synset('african_elephant.n.01'), Synset('gomphothere.n.01'), Synset('indian_elephant.n.01'), Synset('mammoth.n.01'), Synset('rogue_elephant.n.01')]\n",
      "\n",
      "Meronym : [Synset('proboscis.n.02'), Synset('tusk.n.02')]\n",
      "\n",
      "Hypernym : [Synset('emblem.n.02')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "in : [Synset('inch.n.01'), Synset('indium.n.01'), Synset('indiana.n.01'), Synset('in.s.01'), Synset('in.s.02'), Synset('in.s.03'), Synset('in.r.01')]\n",
      "Hypernym : [Synset('linear_unit.n.01')]\n",
      "\n",
      "\n",
      "Meronym : [Synset('em.n.02'), Synset('ligne.n.01'), Synset('mesh.n.01'), Synset('mil.n.03')]\n",
      "\n",
      "Holonym : [Synset('foot.n.02')]\n",
      "Hypernym : [Synset('metallic_element.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Meronym : [Synset('bloomington.n.01'), Synset('evansville.n.01'), Synset('fort_wayne.n.01'), Synset('gary.n.01'), Synset('indianapolis.n.01'), Synset('lafayette.n.03'), Synset('muncie.n.01'), Synset('south_bend.n.01'), Synset('wabash.n.01')]\n",
      "\n",
      "Holonym : [Synset('corn_belt.n.01'), Synset('midwest.n.01'), Synset('united_states.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "my : []\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sleep : [Synset('sleep.n.01'), Synset('sleep.n.02'), Synset('sleep.n.03'), Synset('rest.n.05'), Synset('sleep.v.01'), Synset('sleep.v.02')]\n",
      "Hypernym : [Synset('physical_condition.n.01')]\n",
      "\n",
      "Hyponym : [Synset('orthodox_sleep.n.01'), Synset('paradoxical_sleep.n.01'), Synset('shuteye.n.01'), Synset('sleeping.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('physical_condition.n.01')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('time_period.n.01')]\n",
      "\n",
      "Hyponym : [Synset('beauty_sleep.n.01'), Synset('kip.n.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('death.n.03')]\n",
      "\n",
      "\n",
      "\n",
      "Hypernym : [Synset('rest.v.05')]\n",
      "\n",
      "Hyponym : [Synset('bundle.v.04'), Synset('estivate.v.01'), Synset('hibernate.v.01'), Synset('nap.v.01'), Synset('sleep_late.v.01')]\n",
      "\n",
      "\n",
      "Hypernym : [Synset('accommodate.v.04')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "sent = \"I shot an elephant in my sleep\".split()\n",
    "\n",
    "for s in sent:\n",
    "    synsets = wordnet.synsets(s)\n",
    "    print(\"{} : {}\".format(s, synsets))\n",
    "    for synset in synsets:\n",
    "        hypernym = synset.hypernyms()\n",
    "        hyponym = synset.hyponyms()\n",
    "        meronym = synset.part_meronyms()\n",
    "        holonym = synset.part_holonyms()\n",
    "        \n",
    "        if hypernym:\n",
    "            print(\"Hypernym : {}\".format(hypernym))\n",
    "            pass\n",
    "        print()\n",
    "        \n",
    "        if hyponym:\n",
    "            print(\"Hyponym : {}\".format(hyponym))\n",
    "            pass\n",
    "        print()\n",
    "        \n",
    "        if meronym:\n",
    "            print(\"Meronym : {}\".format(meronym))\n",
    "            pass\n",
    "        print()\n",
    "        \n",
    "        if holonym:\n",
    "            print(\"Holonym : {}\".format(holonym))\n",
    "            pass\n",
    "        pass\n",
    "    print(\"\\n\\n\\n\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
